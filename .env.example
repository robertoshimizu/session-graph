# =============================================================================
# Dev Knowledge Graph - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# -----------------------------------------------------------------------------
# LLM Provider (choose one)
# -----------------------------------------------------------------------------
# Options: gemini, openai, anthropic, ollama
LLM_PROVIDER=gemini
LLM_MODEL=gemini-2.5-flash

# -----------------------------------------------------------------------------
# API Keys (only the one matching your provider is required)
# -----------------------------------------------------------------------------
GEMINI_API_KEY=your-gemini-api-key
# OPENAI_API_KEY=your-openai-api-key
# ANTHROPIC_API_KEY=your-anthropic-api-key
# OLLAMA_BASE_URL=http://localhost:11434  # Default, no key needed

# -----------------------------------------------------------------------------
# Optional: Vertex AI (for bulk_batch.py batch processing, 50% cost discount)
# -----------------------------------------------------------------------------
# GOOGLE_APPLICATION_CREDENTIALS_BASE64=base64-encoded-service-account-json
# GOOGLE_CLOUD_PROJECT=your-gcp-project
# DEVKG_GCS_BUCKET=your-gcs-bucket-name

# -----------------------------------------------------------------------------
# Optional: Fuseki SPARQL Endpoint (for load_fuseki.py)
# -----------------------------------------------------------------------------
# FUSEKI_URL=http://localhost:3030
# FUSEKI_DATASET=devkg
